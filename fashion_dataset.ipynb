{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore and clean the data\n",
    "In this section, we want to explore the data and prepare for image classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 6044: expected 10 fields, saw 11\\nSkipping line 6569: expected 10 fields, saw 11\\nSkipping line 7399: expected 10 fields, saw 11\\nSkipping line 7939: expected 10 fields, saw 11\\nSkipping line 9026: expected 10 fields, saw 11\\nSkipping line 10264: expected 10 fields, saw 11\\nSkipping line 10427: expected 10 fields, saw 11\\nSkipping line 10905: expected 10 fields, saw 11\\nSkipping line 11373: expected 10 fields, saw 11\\nSkipping line 11945: expected 10 fields, saw 11\\nSkipping line 14112: expected 10 fields, saw 11\\nSkipping line 14532: expected 10 fields, saw 11\\nSkipping line 15076: expected 10 fields, saw 12\\nSkipping line 29906: expected 10 fields, saw 11\\nSkipping line 31625: expected 10 fields, saw 11\\nSkipping line 33020: expected 10 fields, saw 11\\nSkipping line 35748: expected 10 fields, saw 11\\nSkipping line 35962: expected 10 fields, saw 11\\nSkipping line 37770: expected 10 fields, saw 11\\nSkipping line 38105: expected 10 fields, saw 11\\nSkipping line 38275: expected 10 fields, saw 11\\nSkipping line 38404: expected 10 fields, saw 12\\n'\n"
     ]
    }
   ],
   "source": [
    "# create a df from styles.csv neglecting lines with error\n",
    "DATASET_PATH = '/mnt/fashion-dataset-1/fashion-dataset/'\n",
    "styles = pd.read_csv(os.path.join(DATASET_PATH, \"styles.csv\"), error_bad_lines=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
      "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
      "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
      "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
      "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
      "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
      "\n",
      "     year   usage                             productDisplayName  \n",
      "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
      "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
      "2  2016.0  Casual                       Titan Women Silver Watch  \n",
      "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
      "4  2012.0  Casual                          Puma Men Grey T-shirt  \n"
     ]
    }
   ],
   "source": [
    "print(styles.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44424\n"
     ]
    }
   ],
   "source": [
    "print(len(styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44442\n"
     ]
    }
   ],
   "source": [
    "# Get the list of names of images that are available\n",
    "imgs_available = os.listdir(DATASET_PATH + '/images')\n",
    "print(len(imgs_available))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to check if each entry in styles.csv has a corresponding images listing. If not, we remove it from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/fashion-dataset-1/fashion-dataset/images/39403.jpg\n",
      "/mnt/fashion-dataset-1/fashion-dataset/images/39410.jpg\n",
      "/mnt/fashion-dataset-1/fashion-dataset/images/39401.jpg\n",
      "/mnt/fashion-dataset-1/fashion-dataset/images/39425.jpg\n",
      "/mnt/fashion-dataset-1/fashion-dataset/images/12347.jpg\n"
     ]
    }
   ],
   "source": [
    "# Check if each entry in styles.csv has a corresponding images listing. \n",
    "# If not, we remove it from the dataframe.\n",
    "missing_img = []\n",
    "for idx, line in styles.iterrows():\n",
    "    if not os.path.exists(os.path.join(DATASET_PATH, 'images', str(line.id)+'.jpg')):\n",
    "        print(os.path.join(DATASET_PATH, 'images', str(line.id)+'.jpg'))\n",
    "        missing_img.append(idx)\n",
    "        \n",
    "styles.drop(styles.index[missing_img], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44419\n"
     ]
    }
   ],
   "source": [
    "print(len(styles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the top articleTypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142\n"
     ]
    }
   ],
   "source": [
    "# Check \n",
    "print(len(styles.groupby(['articleType']).size()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 142 distinct articleTypes. In the next cell we are going to see what are the top 20 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "articleType\n",
      "Jeans                     608\n",
      "Perfume and Body Mist     613\n",
      "Formal Shoes              637\n",
      "Socks                     686\n",
      "Backpacks                 724\n",
      "Belts                     813\n",
      "Briefs                    849\n",
      "Sandals                   897\n",
      "Flip Flops                914\n",
      "Wallets                   936\n",
      "Sunglasses               1073\n",
      "Heels                    1323\n",
      "Handbags                 1759\n",
      "Tops                     1762\n",
      "Kurtas                   1844\n",
      "Sports Shoes             2036\n",
      "Watches                  2542\n",
      "Casual Shoes             2845\n",
      "Shirts                   3215\n",
      "Tshirts                  7066\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "top_classes = styles.groupby(['articleType']).size().nlargest(20).sort_values()\n",
    "print(top_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning / Fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As first, we create master train and test splits of the valid image data, with everything in even years used for the training set, and everything in an odd year used for the test split.\n",
    "Before doing that, we should check if there are any entries with not valid articleType or year and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles.dropna(inplace=True, subset=['year','articleType'])\n",
    "len(styles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = styles[styles['year'].astype('int') % 2 == 0]\n",
    "test = styles[styles['year'].astype('int') % 2 == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next, let us create sub-splits of the training data for pre-training and fine tuning \n",
    "We will do it as follows:\n",
    "* the top 20 classes (see above) - about 3/4 of the data; and\n",
    "* all other classes - about 1/4 of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_classes_names = list(top_classes.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_training = training_data[training_data.articleType.isin(top_classes_names)]\n",
    "fine_tuning = training_data[-training_data.articleType.isin(top_classes_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
